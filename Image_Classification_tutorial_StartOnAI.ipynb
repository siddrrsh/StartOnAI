{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Classification_tutorial_StartOnAI",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddrrsh/StartOnAI/blob/master/Image_Classification_tutorial_StartOnAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8uS_JAfWGOn"
      },
      "source": [
        "# **Image Classification Tutorial in Python**\n",
        "###### Created by **Navein Suresh and Sonnet Xu** for [StartOnAI](https://startonai.com/)\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA8EDDN0Xtlv"
      },
      "source": [
        "## 1. What is Image Classification?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JxN8ixlZRc1"
      },
      "source": [
        "![alt text](https://appsilondatascience.com/assets/uploads/2018/08/types.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70m6nTsAaXFD"
      },
      "source": [
        "- In simple terms, image classification is the ability for someone or something, in this case machines or computers, to recognize a particular object that is put in front of them\n",
        "- It is comparable to how humans are able to identify a particular object, for instance a bananna or an apple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX5hf1YrgCzC"
      },
      "source": [
        "Image Classification Applications\n",
        "  - Face Recgonition used for unlocking phones\n",
        "\n",
        "    <img src=\"https://images.idgesg.net/images/article/2017/09/face-id-setup-100735944-large.jpg\" alt=\"alt text\"  width='340' height='255'>\n",
        "\n",
        "    - Self-driving Cars\n",
        "\n",
        "    <img src=\"https://camo.githubusercontent.com/2e7d64d9ae938a97d5e302c13602ef42940b97a1/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3836382f302a37645265715158456c6e6548425755722e6a7067\" alt=\"alt text\" width=\"600\" height=\"337\">\n",
        "  \n",
        "  - Visual Product Search\n",
        "  \n",
        "  <img src=\"https://imagga.com/blog/wp-content/uploads/2019/05/Visual_Search_lead_image_1920x1080-1024x576.jpg\" alt=\"alt text\"  width='600' height='250'>\n",
        "\n",
        "  - Gaming\n",
        "\n",
        "    <img src=\"https://www.greenmangaming.com/newsroom/wp-content/uploads/2019/10/gaming-blog.jpg\" alt=\"alt text\"  width='340' height='255'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsA-mW5gsJ3w"
      },
      "source": [
        "## 2. Exploring Convolutional Neural Networks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCNMKEjLkpd1"
      },
      "source": [
        "CNNs are short for \"Convolutional Neural Networks\". A CNN is a specfic type of deep learning algorithm that has three general steps associated with it:\n",
        "- Taking an picture/image\n",
        "- Placing weight/biases to particular regions and areas of the image at hand\n",
        "- At the end, the algorithm will allow the machine or computer to differnetiate between various images\n",
        "\n",
        "CNNs aim to boil down an image so that the machine is able to process it, but the algorithm also ensures that it still can output a good prediction.\n",
        "\n",
        "Some differences between a standard neural netwrok and a Convolutional Neyral Network is that the input for a neural network is a vector whereas the input for a CNN is a multi-channeled image.\n",
        "\n",
        "A CNN is made of building blocks known as a convolutional neural network. There are filters present and each one is individually convolved with the image that is inputed.\n",
        "\n",
        "Pictorial Represnetation of a CNN:\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1000/1*bv7EBb98fNmocOkESULgRQ.png\" alt=\"alt text\"  width='600' height='250'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiG2yaOoYwAE"
      },
      "source": [
        "## 3. Explore the Fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nUdqjmn4fOf"
      },
      "source": [
        "Originating from Zalando's articles, the Fashion MNIST Dataset is a dataset whoch contains 60,ooo training sets and 10,000 test sets. The examples are each grayscale, 28 pixels by 28 pixels. \n",
        "\n",
        "Each training and test example is assigned to one of the following labels:\n",
        "\n",
        "- 0 T-shirt/top\n",
        "- 1 Trouser\n",
        "- 2 Pullover\n",
        "- 3 Dress\n",
        "- 4 Coat\n",
        "- 5 Sandal\n",
        "- 6 Shirt\n",
        "- 7 Sneaker\n",
        "- 8 Bag\n",
        "- 9 Ankle boot\n",
        "\n",
        "Fashion MNIST Dataset\n",
        "\n",
        "<img src=\"https://s3-eu-central-1.amazonaws.com/zalando-wp-zalando-research-production/2017/08/fashion-mnist-sprite.png\"  width='600' height='250'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jr07JV7C95k"
      },
      "source": [
        "### 3A. What is a TensorFlow Dataset?\n",
        "Tensorflow datasets are just ready-to-use data sets. These datasets can be used with TensorFlow or other Python ML frameworks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMz8HXo5HKtI"
      },
      "source": [
        "### 3B. Creating Your First CNN w/ the Fashion MNIST Dataset\n",
        "  - Now we're going to classify the Fashion MNIST Dataset with CNNs\n",
        "  - The code is broken down into more manageable sections and described in the comments section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYuMPoL-LJdv"
      },
      "source": [
        "# import neccesary packages\n",
        "import tensorflow as tf\n",
        "# Import TensorFlow Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# Helper libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "# Load the fashion-mnist pre-shuffled train data and test data\n",
        "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']\n",
        "num_train_examples = metadata.splits['train'].num_examples\n",
        "num_test_examples = metadata.splits['test'].num_examples\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\n",
        "print(\"Number of test examples:     {}\".format(num_test_examples))\n",
        "\n",
        "def normalize(images, labels):\n",
        "  images = tf.cast(images, tf.float32)\n",
        "  images /= 255\n",
        "  return images, labels\n",
        "\n",
        "# The map function applies the normalize function to each element in the train\n",
        "# and test datasets\n",
        "train_dataset =  train_dataset.map(normalize)\n",
        "test_dataset  =  test_dataset.map(normalize)\n",
        "\n",
        "# The first time you use the dataset, the images will be loaded from disk\n",
        "# Caching will keep them in memory, making training faster\n",
        "train_dataset =  train_dataset.cache()\n",
        "test_dataset  =  test_dataset.cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pjp0LV9I0pA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "3ac2b5d3-c46f-4305-b821-3ec73b76122a"
      },
      "source": [
        "# now we're going to define the layers of the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "]) \n",
        "\n",
        "# the type of loss depends on the type of problem\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.cache().batch(BATCH_SIZE)\n",
        "model.fit(train_dataset, epochs=10, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))\n",
        "\n",
        "# evaluate accuracy\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_39 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 128)               401536    \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 421,642\n",
            "Trainable params: 421,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 73s 39ms/step - loss: 0.4008 - accuracy: 0.8546\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 72s 39ms/step - loss: 0.2615 - accuracy: 0.9053\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.2105 - accuracy: 0.9237\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 71s 38ms/step - loss: 0.1834 - accuracy: 0.9331\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.1546 - accuracy: 0.9425\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 71s 38ms/step - loss: 0.1336 - accuracy: 0.9505\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 71s 38ms/step - loss: 0.1101 - accuracy: 0.9586\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.0914 - accuracy: 0.9658\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.0788 - accuracy: 0.9708\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.0685 - accuracy: 0.9750\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3188 - accuracy: 0.9191\n",
            "Accuracy on test dataset: 0.9190999865531921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-qJBTOpXM7u"
      },
      "source": [
        "## Sources:\n",
        "- udacity.com\n",
        "- https://www.analyticsvidhya.com/blog/2019/01/build-image-classification-model-10-minutes/\n",
        "- https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8\n",
        "- https://www.tensorflow.org/datasets/catalog/fashion_mnist#:~:text=Fashion%2DMNIST%20is%20a%20dataset,a%20label%20from%2010%20classes.\n",
        "\n",
        "\n",
        "#### Pictures\n",
        "\n",
        "- https://appsilondatascience.com/assets/uploads/2018/08/types.png\n",
        "- https://images.idgesg.net/images/article/2017/09/face-id-setup-100735944-large.jpg\n",
        "- https://camo.githubusercontent.com/2e7d64d9ae938a97d5e302c13602ef42940b97a1/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3836382f302a37645265715158456c6e6548425755722e6a7067\n",
        "- https://imagga.com/blog/wp-content/uploads/2019/05/Visual_Search_lead_image_1920x1080-1024x576.jpg\n",
        "- https://www.greenmangaming.com/newsroom/wp-content/uploads/2019/10/gaming-blog.jpg\n",
        "- https://miro.medium.com/max/1000/1*bv7EBb98fNmocOkESULgRQ.png\" \n",
        "- https://s3-eu-central-1.amazonaws.com/zalando-wp-zalando-research-production/2017/08/fashion-mnist-sprite.png\n",
        "- https://www.analyticsvidhya.com/blog/2019/01/build-image-classification-model-10-minutes/\n"
      ]
    }
  ]
}